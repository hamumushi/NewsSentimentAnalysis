{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis by RRN with LSTM Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [LSTM-Sentiment-Analysis](https://github.com/adeshpande3/LSTM-Sentiment-Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding\n",
    "\n",
    "from random import randint\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 (default, Jul 18 2018, 11:31:17) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading words list and word vectors\n",
    "\n",
    "- We downloaded wordsList_glove_dim200.npy and wordVectors_glove_dim200.npy from [GloVe](http://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "- We made wordsList_TR.npy and wordVectors_TR.npy from Thomson Reuters News Archive from 2003 to 2016 (8856M words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of word list:  400000\n",
      "float32\n",
      "Shape of word vectors:  (400000, 200)\n",
      "Dimensions for each word vector:  200\n",
      "numDimensions =  200\n"
     ]
    }
   ],
   "source": [
    "wordsList = np.load('wordsList_glove_dim200.npy').tolist()\n",
    "#wordsList = np.load('wordsList_TR.npy').tolist()\n",
    "print('Length of word list: ',len(wordsList))\n",
    "\n",
    "wordVectors = np.load('wordVectors_glove_dim200.npy')\n",
    "#wordVectors = np.load('wordVectors_TR.npy')\n",
    "print(wordVectors.dtype)\n",
    "\n",
    "print('Shape of word vectors: ',wordVectors.shape)\n",
    "print('Dimensions for each word vector: ',wordVectors.shape[1])\n",
    "numDimensions = wordVectors.shape[1] #Dimensions for each word vector\n",
    "print('numDimensions = ',numDimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading positive documents and negative documents\n",
    "\n",
    "- Users must prepare positive documents ond negative documents by yourself.\n",
    "\n",
    "- In this git, positiveDocs.zip and negativeDocs.zip are movie reviews ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:21<00:00, 580.51it/s] \n",
      "100%|██████████| 12500/12500 [00:32<00:00, 389.01it/s] \n"
     ]
    }
   ],
   "source": [
    "positiveFiles = glob.glob('positiveDocs/*')\n",
    "negativeFiles = glob.glob('negativeDocs/*')\n",
    "def read_files(file_paths):\n",
    "    texts=[]\n",
    "    for path in tqdm(file_paths):\n",
    "        with open(path, \"r\", encoding='utf-8') as f:\n",
    "            texts.append(f.readline())\n",
    "    return texts\n",
    "\n",
    "positive_texts = read_files(positiveFiles)\n",
    "negative_texts = read_files(negativeFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.DataFrame(positive_texts, columns=['text'])\n",
    "df_positive['sentiment'] = 1\n",
    "df_negative = pd.DataFrame(negative_texts, columns=['text'])\n",
    "df_negative['sentiment'] = -1\n",
    "df = pd.concat([df_positive, df_negative]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleanedText'] = df['text'].apply(cleanSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>Stocks on the move [HOT-RTRS] Real-time Equity...</td>\n",
       "      <td>-1</td>\n",
       "      <td>stocks on the move hotrtrs realtime equity new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>(Adds Apple, Forest, updates prices) NEW YORK,...</td>\n",
       "      <td>-1</td>\n",
       "      <td>adds apple forest updates prices new york nov ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>(Adds byline, analyst quote, details) By Bill ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>adds byline analyst quote details by bill rigb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>SAN FRANCISCO, July 13 (Reuters) - Apple Compu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>san francisco july 13 reuters  apple computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>Stocks on the move [HOT-RTRS] Real-time Equity...</td>\n",
       "      <td>-1</td>\n",
       "      <td>stocks on the move hotrtrs realtime equity new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>* Q2 EPS $0.25 vs est $0.27 * Q2 was $114 mln ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>q2 eps 025 vs est 027  q2 was 114 mln vs est ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>By Eric Onstad AMSTERDAM, May 5 (Reuters) - A ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>by eric onstad amsterdam may 5 reuters  a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>NEW YORK, July 31 (Reuters) - Wachovia Corp &lt;W...</td>\n",
       "      <td>-1</td>\n",
       "      <td>new york july 31 reuters  wachovia corp wbn sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>FARNBOROUGH, England, July 14 (Reuters) - An o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>farnborough england july 14 reuters  an order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>By Bernhard Warner, European Internet Correspo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>by bernhard warner european internet correspon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "24990  Stocks on the move [HOT-RTRS] Real-time Equity...         -1   \n",
       "24991  (Adds Apple, Forest, updates prices) NEW YORK,...         -1   \n",
       "24992  (Adds byline, analyst quote, details) By Bill ...         -1   \n",
       "24993  SAN FRANCISCO, July 13 (Reuters) - Apple Compu...         -1   \n",
       "24994  Stocks on the move [HOT-RTRS] Real-time Equity...         -1   \n",
       "24995  * Q2 EPS $0.25 vs est $0.27 * Q2 was $114 mln ...         -1   \n",
       "24996  By Eric Onstad AMSTERDAM, May 5 (Reuters) - A ...         -1   \n",
       "24997  NEW YORK, July 31 (Reuters) - Wachovia Corp <W...         -1   \n",
       "24998  FARNBOROUGH, England, July 14 (Reuters) - An o...         -1   \n",
       "24999  By Bernhard Warner, European Internet Correspo...         -1   \n",
       "\n",
       "                                             cleanedText  \n",
       "24990  stocks on the move hotrtrs realtime equity new...  \n",
       "24991  adds apple forest updates prices new york nov ...  \n",
       "24992  adds byline analyst quote details by bill rigb...  \n",
       "24993  san francisco july 13 reuters  apple computer ...  \n",
       "24994  stocks on the move hotrtrs realtime equity new...  \n",
       "24995   q2 eps 025 vs est 027  q2 was 114 mln vs est ...  \n",
       "24996  by eric onstad amsterdam may 5 reuters  a new ...  \n",
       "24997  new york july 31 reuters  wachovia corp wbn sa...  \n",
       "24998  farnborough england july 14 reuters  an order ...  \n",
       "24999  by bernhard warner european internet correspon...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 74091)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=3, max_df=0.98)\n",
    "text_onehot = vectorizer.fit_transform(df['cleanedText'].values)\n",
    "print(text_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44786, 68462]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleanedText</th>\n",
       "      <th>text_toid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks on the move [HOT-RTRS] Real-time Equity...</td>\n",
       "      <td>1</td>\n",
       "      <td>stocks on the move hotrtrs realtime equity new...</td>\n",
       "      <td>[66507, 52349, 39752, 59985, 33644, 53468, 609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real-time equity news [U E] U.S. stock market ...</td>\n",
       "      <td>1</td>\n",
       "      <td>realtime equity news u e us stock market repor...</td>\n",
       "      <td>[59985, 33644, 53468, 71063, 66481, 50213, 608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March 16 (Reuters) - Nearly two years ago, act...</td>\n",
       "      <td>1</td>\n",
       "      <td>march 16 reuters  nearly two years ago activis...</td>\n",
       "      <td>[50125, 5806, 61225, 53202, 70141, 73725, 1944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06 Nov Q3 AutoNation &lt;AN&gt; 0.29 11 0.39 06 Nov ...</td>\n",
       "      <td>1</td>\n",
       "      <td>06 nov q3 autonation an 029 11 039 06 nov q3 b...</td>\n",
       "      <td>[1078, 54399, 59167, 21875, 450, 2926, 617, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Recasts first paragraph, adds details SAN FRA...</td>\n",
       "      <td>1</td>\n",
       "      <td>recasts first paragraph adds details san franc...</td>\n",
       "      <td>[60075, 35513, 56257, 18985, 30768, 62803, 362...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  Stocks on the move [HOT-RTRS] Real-time Equity...          1   \n",
       "1  Real-time equity news [U E] U.S. stock market ...          1   \n",
       "2  March 16 (Reuters) - Nearly two years ago, act...          1   \n",
       "3  06 Nov Q3 AutoNation <AN> 0.29 11 0.39 06 Nov ...          1   \n",
       "4  (Recasts first paragraph, adds details SAN FRA...          1   \n",
       "\n",
       "                                         cleanedText  \\\n",
       "0  stocks on the move hotrtrs realtime equity new...   \n",
       "1  realtime equity news u e us stock market repor...   \n",
       "2  march 16 reuters  nearly two years ago activis...   \n",
       "3  06 nov q3 autonation an 029 11 039 06 nov q3 b...   \n",
       "4  recasts first paragraph adds details san franc...   \n",
       "\n",
       "                                           text_toid  \n",
       "0  [66507, 52349, 39752, 59985, 33644, 53468, 609...  \n",
       "1  [59985, 33644, 53468, 71063, 66481, 50213, 608...  \n",
       "2  [50125, 5806, 61225, 53202, 70141, 73725, 1944...  \n",
       "3  [1078, 54399, 59167, 21875, 450, 2926, 617, 10...  \n",
       "4  [60075, 35513, 56257, 18985, 30768, 62803, 362...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "tokenize = vectorizer.build_tokenizer()\n",
    "preprocess = vectorizer.build_preprocessor()\n",
    " \n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    " \n",
    "print(to_sequence(tokenize, preprocess, word2idx, \"This is an important test!\"))  # [2269, 4453]\n",
    "df['text_toid'] = [to_sequence(tokenize, preprocess, word2idx, x) for x in df['cleanedText'].values]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['text_toid'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       325.504040\n",
       "std        208.537934\n",
       "min         32.000000\n",
       "25%        159.000000\n",
       "50%        304.000000\n",
       "75%        433.000000\n",
       "max       1215.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 550)\n"
     ]
    }
   ],
   "source": [
    "maxSeqLength = 550\n",
    "N_FEATURES = len(vectorizer.get_feature_names())\n",
    "texts_padding = pad_sequences(df['text_toid'].values, maxlen=maxSeqLength, value=N_FEATURES)\n",
    "#print(texts_padding[0])\n",
    "ids = texts_padding\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499,24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with LSTM Units Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-16-9cfbb006d8de>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-16-9cfbb006d8de>:11: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-773132a4e1b5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "#with tf.Session() as sess:\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users enter 'tensorboard --logdir=tensorboard' on your terminal and visit http://localhost:6006/ with a browser to keep an eye on your training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to models_kai/pretrained_lstm.ckpt-10000\n",
      "saved to models_kai/pretrained_lstm.ckpt-20000\n",
      "saved to models_kai/pretrained_lstm.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "   #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "   #Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "   #Save the network every 1,000 training iterations\n",
    "    if (i % 10000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
